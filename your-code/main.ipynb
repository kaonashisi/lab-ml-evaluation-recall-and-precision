{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "## Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics\n",
    "### We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', parser='auto')\n",
    "X, y = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Also, I think the original just loaded in as np.array directly and here we have a dataframe and series. So when we are looking for a specific row we can use the .iloc attribute.And we can convert a pandas dataseries to a numpy array with:\\n\\nnp.array(somedataseries)\\n\\nThis will give us access to numpy methods such as reshape (mentioned in the lab)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Also, I think the original just loaded in as np.array directly and here we have a dataframe and series. So when we are looking for a specific row we can use the .iloc attribute.And we can convert a pandas dataseries to a numpy array with:\n",
    "\n",
    "np.array(somedataseries)\n",
    "\n",
    "This will give us access to numpy methods such as reshape (mentioned in the lab)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now take a look at the shapes of the X and y matricies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's pick one entry and see what number is written. Use indexing to pick the 36000th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "pixel4      0\n",
       "pixel5      0\n",
       "           ..\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "pixel784    0\n",
       "Name: 36000, Length: 784, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X.iloc[36000], y.iloc[36000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use the .reshape(28,28) function and plt.imshow() function with the parameters cmap = matplotlib.cm.binary, interpolation=\"nearest\" to make a plot of the number. Be sure to import matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbJ0lEQVR4nO3df2zU9R3H8dfxoydoe12t7bWjdAUVpkC3MaiNynBU2m4jIPwharLiCARXnFidpouKui11mDGjY7gsCnMRZC4CyjImVlt0tiwghBG3hjZ14KBlErkrRUqln/1BvHlSfnyPu7575flIvgm9+356b79+7dMvvX7rc845AQDQxwZZDwAAuDgRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYGKI9QBf1NPTowMHDig1NVU+n896HACAR845dXR0KDc3V4MGnfk6p98F6MCBA8rLy7MeAwBwgfbv368RI0ac8fl+F6DU1FRJpwZPS0szngYA4FU4HFZeXl7k6/mZJCxAK1as0JNPPqm2tjYVFhbqmWee0eTJk8+57rO/dktLSyNAAJDEzvVtlIS8CWHdunWqqqrS0qVL9d5776mwsFClpaU6dOhQIl4OAJCEEhKg5cuXa8GCBbrzzjt1zTXX6Nlnn9Xw4cP1/PPPJ+LlAABJKO4BOnHihHbs2KGSkpL/v8igQSopKVFDQ8Np+3d1dSkcDkdtAICBL+4B+uijj3Ty5EllZ2dHPZ6dna22trbT9q+pqVEgEIhsvAMOAC4O5j+IWl1drVAoFNn2799vPRIAoA/E/V1wmZmZGjx4sNrb26Meb29vVzAYPG1/v98vv98f7zEAAP1c3K+AUlJSNHHiRNXW1kYe6+npUW1trYqLi+P9cgCAJJWQnwOqqqpSRUWFvvnNb2ry5Ml66qmn1NnZqTvvvDMRLwcASEIJCdCtt96q//73v3rkkUfU1tamr33ta9q8efNpb0wAAFy8fM45Zz3E54XDYQUCAYVCIe6EAABJ6Hy/jpu/Cw4AcHEiQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAm4h6gRx99VD6fL2obO3ZsvF8GAJDkhiTik1577bV64403/v8iQxLyMgCAJJaQMgwZMkTBYDARnxoAMEAk5HtAe/fuVW5urkaNGqU77rhD+/btO+O+XV1dCofDURsAYOCLe4CKioq0evVqbd68WStXrlRra6tuvPFGdXR09Lp/TU2NAoFAZMvLy4v3SACAfsjnnHOJfIEjR44oPz9fy5cv1/z58097vqurS11dXZGPw+Gw8vLyFAqFlJaWlsjRAAAJEA6HFQgEzvl1POHvDkhPT9fVV1+t5ubmXp/3+/3y+/2JHgMA0M8k/OeAjh49qpaWFuXk5CT6pQAASSTuAbr//vtVX1+vDz74QO+++65uueUWDR48WLfddlu8XwoAkMTi/ldwH374oW677TYdPnxYV1xxhW644QY1NjbqiiuuiPdLAQCSWNwD9NJLL8X7UwLoY59++qnnNT/60Y88r1m5cqXnNaWlpZ7X/OlPf/K8RpIuu+yymNbh/HAvOACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADARMJ/IR2A+Ojs7PS85uc//3lMr/Xqq696XvP+++97XuPz+Tyvef311z2vWbNmjec1krRw4cKY1uH8cAUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9wNGzDw/e9/3/OaP//5z57XfPzxx57XDESFhYXWI6AXXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GSnwOS0tLZ7XVFRUeF7z7rvvel6DUwKBgOc1V111VQImwYXiCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSDEgrV27NqZ18+bN87ymu7s7ptfqCzfffHNM67Zs2RLnSXo3Y8YMz2t++9vfel6TkZHheQ0SjysgAIAJAgQAMOE5QFu3btWMGTOUm5srn8+nDRs2RD3vnNMjjzyinJwcDRs2TCUlJdq7d2+85gUADBCeA9TZ2anCwkKtWLGi1+eXLVump59+Ws8++6y2bdumSy+9VKWlpTp+/PgFDwsAGDg8vwmhvLxc5eXlvT7nnNNTTz2lhx56SDNnzpQkvfDCC8rOztaGDRs0d+7cC5sWADBgxPV7QK2trWpra1NJSUnksUAgoKKiIjU0NPS6pqurS+FwOGoDAAx8cQ1QW1ubJCk7Ozvq8ezs7MhzX1RTU6NAIBDZ8vLy4jkSAKCfMn8XXHV1tUKhUGTbv3+/9UgAgD4Q1wAFg0FJUnt7e9Tj7e3tkee+yO/3Ky0tLWoDAAx8cQ1QQUGBgsGgamtrI4+Fw2Ft27ZNxcXF8XwpAECS8/wuuKNHj6q5uTnycWtrq3bt2qWMjAyNHDlSS5Ys0c9+9jNdddVVKigo0MMPP6zc3FzNmjUrnnMDAJKc5wBt375dN910U+TjqqoqSVJFRYVWr16tBx54QJ2dnVq4cKGOHDmiG264QZs3b9Yll1wSv6kBAEnP55xz1kN8XjgcViAQUCgU4vtBkCQtXbrU85ply5bF9FpdXV0xrfMqlp+JS09P97ymsbHR8xpJ2rVrl+c19913n+c1TzzxhOc1gwcP9rwGfet8v46bvwsOAHBxIkAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAnPv44BuBBr1671vCaWO1vHelfrWO7Afvfdd3teM2HCBM9rHnzwQc9rPvjgA89rYlVUVOR5DXe2vrhxBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBmpIjZp59+6nnN888/73lNrDcWjUUsN8c8fvy45zVz5871vMY553kN0J9xBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBmpIjZxx9/7HlNbW1tAiaJn1j+mX75y18mYBJbKSkpntfk5+cnYBIMZFwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkpYvbqq69aj5C0xowZ43lNU1NTAibp3c033+x5zaRJkxIwCQYyroAAACYIEADAhOcAbd26VTNmzFBubq58Pp82bNgQ9fy8efPk8/mitrKysnjNCwAYIDwHqLOzU4WFhVqxYsUZ9ykrK9PBgwcj29q1ay9oSADAwOP5TQjl5eUqLy8/6z5+v1/BYDDmoQAAA19CvgdUV1enrKwsjRkzRnfddZcOHz58xn27uroUDoejNgDAwBf3AJWVlemFF15QbW2tfvGLX6i+vl7l5eU6efJkr/vX1NQoEAhEtry8vHiPBADoh+L+c0Bz586N/Hn8+PGaMGGCRo8erbq6Ok2bNu20/aurq1VVVRX5OBwOEyEAuAgk/G3Yo0aNUmZmppqbm3t93u/3Ky0tLWoDAAx8CQ/Qhx9+qMOHDysnJyfRLwUASCKe/wru6NGjUVczra2t2rVrlzIyMpSRkaHHHntMc+bMUTAYVEtLix544AFdeeWVKi0tjevgAIDk5jlA27dv10033RT5+LPv31RUVGjlypXavXu3fv/73+vIkSPKzc3V9OnT9dOf/lR+vz9+UwMAkp7nAE2dOlXOuTM+/9e//vWCBkLyqKio8Lxm3bp1nte89dZbntec6V2X5zJ06FDPa773ve95XhPLzUifeOIJz2tidc011/TZa+Hixb3gAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCLuv5IbF48hQ7yfPq+//rrnNTt37vS85h//+IfnNVL0r5Q/XykpKZ7XjBs3zvOavvSDH/zAegRcBLgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNS9Htf//rX+2RNrB5//HHPa95///0ETHK66667LqZ1BQUFcZ4EOB1XQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GCnzOf/7zH89rfv3rXydgkvhYtGhRTOtSUlLiPAlwOq6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3IwU+Jy//OUvntd89NFHCZjkdIFAwPOaOXPmJGASID64AgIAmCBAAAATngJUU1OjSZMmKTU1VVlZWZo1a5aampqi9jl+/LgqKyt1+eWX67LLLtOcOXPU3t4e16EBAMnPU4Dq6+tVWVmpxsZGbdmyRd3d3Zo+fbo6Ozsj+9x777167bXX9PLLL6u+vl4HDhzQ7Nmz4z44ACC5eXoTwubNm6M+Xr16tbKysrRjxw5NmTJFoVBIzz33nNasWaNvf/vbkqRVq1bpq1/9qhobG3XdddfFb3IAQFK7oO8BhUIhSVJGRoYkaceOHeru7lZJSUlkn7Fjx2rkyJFqaGjo9XN0dXUpHA5HbQCAgS/mAPX09GjJkiW6/vrrNW7cOElSW1ubUlJSlJ6eHrVvdna22traev08NTU1CgQCkS0vLy/WkQAASSTmAFVWVmrPnj166aWXLmiA6upqhUKhyLZ///4L+nwAgOQQ0w+iLl68WJs2bdLWrVs1YsSIyOPBYFAnTpzQkSNHoq6C2tvbFQwGe/1cfr9ffr8/ljEAAEnM0xWQc06LFy/W+vXr9eabb6qgoCDq+YkTJ2ro0KGqra2NPNbU1KR9+/apuLg4PhMDAAYET1dAlZWVWrNmjTZu3KjU1NTI93UCgYCGDRumQCCg+fPnq6qqShkZGUpLS9Pdd9+t4uJi3gEHAIjiKUArV66UJE2dOjXq8VWrVmnevHmSpF/96lcaNGiQ5syZo66uLpWWluo3v/lNXIYFAAwcPuecsx7i88LhsAKBgEKhkNLS0qzHQZJ6++23Y1r3+R8hOF/d3d0xvZZX69ev97xm5syZCZgEOLvz/TrOveAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgIqbfiAr0pVjuNr1r164+e61Y3HjjjZ7XfPe7303AJIAdroAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjBT93ttvv+15zT333JOASeLnD3/4g+c1Q4bwnysGFq6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3N0Q/d769eutRzirsrIyz2tGjBiRgEmA5MIVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRok8999xzntf87ne/S8AkvcvPz/e8Zt26dZ7XDBrE//sB/FcAADBBgAAAJjwFqKamRpMmTVJqaqqysrI0a9YsNTU1Re0zdepU+Xy+qG3RokVxHRoAkPw8Bai+vl6VlZVqbGzUli1b1N3drenTp6uzszNqvwULFujgwYORbdmyZXEdGgCQ/Dy9CWHz5s1RH69evVpZWVnasWOHpkyZEnl8+PDhCgaD8ZkQADAgXdD3gEKhkCQpIyMj6vEXX3xRmZmZGjdunKqrq3Xs2LEzfo6uri6Fw+GoDQAw8MX8Nuyenh4tWbJE119/vcaNGxd5/Pbbb1d+fr5yc3O1e/duPfjgg2pqatIrr7zS6+epqanRY489FusYAIAkFXOAKisrtWfPHr3zzjtRjy9cuDDy5/HjxysnJ0fTpk1TS0uLRo8efdrnqa6uVlVVVeTjcDisvLy8WMcCACSJmAK0ePFibdq0SVu3btWIESPOum9RUZEkqbm5udcA+f1++f3+WMYAACQxTwFyzunuu+/W+vXrVVdXp4KCgnOu2bVrlyQpJycnpgEBAAOTpwBVVlZqzZo12rhxo1JTU9XW1iZJCgQCGjZsmFpaWrRmzRp95zvf0eWXX67du3fr3nvv1ZQpUzRhwoSE/AMAAJKTpwCtXLlS0qkfNv28VatWad68eUpJSdEbb7yhp556Sp2dncrLy9OcOXP00EMPxW1gAMDA4Pmv4M4mLy9P9fX1FzQQAODi4HPnqkofC4fDCgQCCoVCSktLsx4HAODR+X4d52akAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmBhiPcAXOeckSeFw2HgSAEAsPvv6/dnX8zPpdwHq6OiQJOXl5RlPAgC4EB0dHQoEAmd83ufOlag+1tPTowMHDig1NVU+ny/quXA4rLy8PO3fv19paWlGE9rjOJzCcTiF43AKx+GU/nAcnHPq6OhQbm6uBg0683d6+t0V0KBBgzRixIiz7pOWlnZRn2Cf4TicwnE4heNwCsfhFOvjcLYrn8/wJgQAgAkCBAAwkVQB8vv9Wrp0qfx+v/UopjgOp3AcTuE4nMJxOCWZjkO/exMCAODikFRXQACAgYMAAQBMECAAgAkCBAAwkTQBWrFihb7yla/okksuUVFRkf7+979bj9TnHn30Ufl8vqht7Nix1mMl3NatWzVjxgzl5ubK5/Npw4YNUc875/TII48oJydHw4YNU0lJifbu3WszbAKd6zjMmzfvtPOjrKzMZtgEqamp0aRJk5SamqqsrCzNmjVLTU1NUfscP35clZWVuvzyy3XZZZdpzpw5am9vN5o4Mc7nOEydOvW082HRokVGE/cuKQK0bt06VVVVaenSpXrvvfdUWFio0tJSHTp0yHq0Pnfttdfq4MGDke2dd96xHinhOjs7VVhYqBUrVvT6/LJly/T000/r2Wef1bZt23TppZeqtLRUx48f7+NJE+tcx0GSysrKos6PtWvX9uGEiVdfX6/Kyko1NjZqy5Yt6u7u1vTp09XZ2RnZ595779Vrr72ml19+WfX19Tpw4IBmz55tOHX8nc9xkKQFCxZEnQ/Lli0zmvgMXBKYPHmyq6ysjHx88uRJl5ub62pqagyn6ntLly51hYWF1mOYkuTWr18f+binp8cFg0H35JNPRh47cuSI8/v9bu3atQYT9o0vHgfnnKuoqHAzZ840mcfKoUOHnCRXX1/vnDv1737o0KHu5Zdfjuzzz3/+00lyDQ0NVmMm3BePg3POfetb33L33HOP3VDnod9fAZ04cUI7duxQSUlJ5LFBgwappKREDQ0NhpPZ2Lt3r3JzczVq1Cjdcccd2rdvn/VIplpbW9XW1hZ1fgQCARUVFV2U50ddXZ2ysrI0ZswY3XXXXTp8+LD1SAkVCoUkSRkZGZKkHTt2qLu7O+p8GDt2rEaOHDmgz4cvHofPvPjii8rMzNS4ceNUXV2tY8eOWYx3Rv3uZqRf9NFHH+nkyZPKzs6Oejw7O1v/+te/jKayUVRUpNWrV2vMmDE6ePCgHnvsMd14443as2ePUlNTrccz0dbWJkm9nh+fPXexKCsr0+zZs1VQUKCWlhb95Cc/UXl5uRoaGjR48GDr8eKup6dHS5Ys0fXXX69x48ZJOnU+pKSkKD09PWrfgXw+9HYcJOn2229Xfn6+cnNztXv3bj344INqamrSK6+8YjhttH4fIPxfeXl55M8TJkxQUVGR8vPz9cc//lHz5883nAz9wdy5cyN/Hj9+vCZMmKDRo0errq5O06ZNM5wsMSorK7Vnz56L4vugZ3Om47Bw4cLIn8ePH6+cnBxNmzZNLS0tGj16dF+P2at+/1dwmZmZGjx48GnvYmlvb1cwGDSaqn9IT0/X1VdfrebmZutRzHx2DnB+nG7UqFHKzMwckOfH4sWLtWnTJr311ltRv74lGAzqxIkTOnLkSNT+A/V8ONNx6E1RUZEk9avzod8HKCUlRRMnTlRtbW3ksZ6eHtXW1qq4uNhwMntHjx5VS0uLcnJyrEcxU1BQoGAwGHV+hMNhbdu27aI/Pz788EMdPnx4QJ0fzjktXrxY69ev15tvvqmCgoKo5ydOnKihQ4dGnQ9NTU3at2/fgDofznUcerNr1y5J6l/ng/W7IM7HSy+95Px+v1u9erV7//333cKFC116erpra2uzHq1P3Xfffa6urs61tra6v/3tb66kpMRlZma6Q4cOWY+WUB0dHW7nzp1u586dTpJbvny527lzp/v3v//tnHPuiSeecOnp6W7jxo1u9+7dbubMma6goMB98sknxpPH19mOQ0dHh7v//vtdQ0ODa21tdW+88Yb7xje+4a666ip3/Phx69Hj5q677nKBQMDV1dW5gwcPRrZjx45F9lm0aJEbOXKke/PNN9327dtdcXGxKy4uNpw6/s51HJqbm93jjz/utm/f7lpbW93GjRvdqFGj3JQpU4wnj5YUAXLOuWeeecaNHDnSpaSkuMmTJ7vGxkbrkfrcrbfe6nJyclxKSor78pe/7G699VbX3NxsPVbCvfXWW07SaVtFRYVz7tRbsR9++GGXnZ3t/H6/mzZtmmtqarIdOgHOdhyOHTvmpk+f7q644go3dOhQl5+f7xYsWDDg/iett39+SW7VqlWRfT755BP3wx/+0H3pS19yw4cPd7fccos7ePCg3dAJcK7jsG/fPjdlyhSXkZHh/H6/u/LKK92Pf/xjFwqFbAf/An4dAwDARL//HhAAYGAiQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEz8D4sblA79J1X5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = X.values.reshape(X.values.shape[0], 28, 28, 1)\n",
    "#y_train = \n",
    "image = X_train[36000]\n",
    "\n",
    "# plot the sample\n",
    "fig = plt.figure\n",
    "plt.imshow(image, cmap=plt.cm.binary, interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use indexing to see if what the plot shows matches with the outcome of the 36000th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y[36000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training/testing sets\n",
    "X_train = X[:60000]\n",
    "X_test = X[60000:]\n",
    "# Use only one feature\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "y_train = y[:60000]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = y_train.apply(lambda x: x if x == '5' else '-1')\n",
    "y_test_5 = y_test.apply(lambda x: x if x == '5' else '-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets train a logistic regression to predict if a number is a 5 or not (remember to use the 'just 5s' y training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sirinekefi/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['-1', '-1', '-1', ..., '-1', '5', '-1'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[9.99773668e-01, 2.26331913e-04],\n",
       "       [9.61298259e-01, 3.87017412e-02],\n",
       "       [9.92695576e-01, 7.30442394e-03],\n",
       "       ...,\n",
       "       [9.97817008e-01, 2.18299160e-03],\n",
       "       [3.38356263e-03, 9.96616437e-01],\n",
       "       [9.99846903e-01, 1.53097070e-04]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9778166666666667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train_5)\n",
    "pred = clf.predict(X_test)\n",
    "pred_proba = clf.predict_proba(X_test)\n",
    "score = clf.score(X_train, y_train_5)\n",
    "display(pred, len(pred), pred_proba, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sirinekefi/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['-1'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_train.iloc[36000].array.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below, and call it using: never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets fit and predict on the testing set using our never 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m new_clf \u001b[38;5;241m=\u001b[39m never_5_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m----> 2\u001b[0m new_pred \u001b[38;5;241m=\u001b[39m \u001b[43mnew_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(X_test)\n\u001b[1;32m      3\u001b[0m display(new_cl, new_pred)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "new_clf = never_5_clf.fit(X_train, y_train)\n",
    "new_pred = new_clf.predict(X_test)\n",
    "display(new_cl, new_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
